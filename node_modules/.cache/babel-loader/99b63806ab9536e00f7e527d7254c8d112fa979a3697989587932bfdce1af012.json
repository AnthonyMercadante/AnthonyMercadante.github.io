{"ast":null,"code":"var _jsxFileName = \"A:\\\\Projects\\\\AnthonyMercadante.github.io\\\\src\\\\components\\\\RealEstateBot\\\\RealEstateBot.tsx\",\n  _s = $RefreshSig$();\nimport React from 'react';\nimport { Box, Typography, useTheme } from '@mui/material';\nimport { useNavigate } from 'react-router-dom';\nimport { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';\nimport { dark } from 'react-syntax-highlighter/dist/esm/styles/prism';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst RealEstateBot = () => {\n  _s();\n  const navigate = useNavigate();\n  const theme = useTheme();\n  const customDarkTheme = {\n    ...dark,\n    // Override specific styles. Example:\n    'code[class*=\"language-\"]': {\n      ...dark['code[class*=\"language-\"]'],\n      color: '#f8f8f2',\n      background: 'none',\n      fontSize: '1em',\n      textAlign: 'left',\n      wordSpacing: 'normal',\n      wordBreak: 'normal',\n      wordWrap: 'normal',\n      lineHeight: '1.5',\n      tabSize: '4',\n      hyphens: 'none'\n    }\n    // Add additional customizations as needed\n  };\n  const pythonCode = `Created by Anthony Mercadante\n    Date: November 2023\n    \"\"\"\n    \n    from openai import OpenAI\n    import os\n    import spacy\n    from sklearn.feature_extraction.text import CountVectorizer\n    \n    # Initialize the OpenAI client with the API key from environment variables\n    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n    \n    # Load the spaCy language model\n    nlp = spacy.load(\"en_core_web_sm\")\n    \n    # Global variable to maintain the conversation history\n    conversation_history = []\n    \n    def analyze_word_frequency(utterance):\n        \"\"\"\n        Analyzes the frequency of words in the given utterance.\n    \n        Args:\n            utterance (str): The user's input message.\n    \n        Returns:\n            dict: A dictionary of word frequencies.\n        \"\"\"\n        doc = nlp(utterance)\n        vectorizer = CountVectorizer()\n        vectorized_words = vectorizer.fit_transform([utterance])\n        word_freq = dict(zip(vectorizer.get_feature_names_out(), vectorized_words.toarray().tolist()[0]))\n        return word_freq\n    \n    def classify_utterance(utterance):\n        \"\"\"\n        Classifies the given utterance into categories like emotional tone or speech act.\n        Placeholder function - actual implementation required.\n    \n        Args:\n            utterance (str): The user's input message.\n    \n        Returns:\n            str: The classified category of the utterance.\n        \"\"\"\n        # Placeholder: Implement a classifier or use an existing model\n        return \"general_inquiry\"\n    \n    def ask_openai(utterance):\n        \"\"\"\n        Processes the given user utterance and generates a response using OpenAI's API.\n    \n        Args:\n            utterance (str): The user's input message.\n    \n        Returns:\n            str: The generated response from the bot.\n        \"\"\"\n        global conversation_history\n        # Analyze word frequency and classify utterance\n        word_freq = analyze_word_frequency(utterance)\n        utterance_category = classify_utterance(utterance)\n    \n        # Append the user's utterance and additional info to the conversation history\n        conversation_history.append({\"role\": \"user\", \"content\": utterance, \"word_freq\": word_freq, \"category\": utterance_category})\n    \n        try:\n            # Construct a prompt for the completion model\n            prompt = create_completion_prompt(utterance)\n            # Set a maximum token limit for the prompt\n            max_prompt_tokens = 500\n            prompt_length = len(prompt.split())\n            remaining_tokens = max(20, max_prompt_tokens - prompt_length)\n    \n            # Make a call to the completion model\n            response_completion = client.completions.create(\n                model=\"text-davinci-003\",\n                prompt=prompt,\n                temperature=0.7,\n                max_tokens=remaining_tokens\n            )\n            # Extract and clean the response\n            completion_response = response_completion.choices[0].text.strip()\n            # Append the response to the conversation history\n            conversation_history.append({\"role\": \"assistant\", \"content\": completion_response})\n        except Exception as e:\n            # Handle exceptions and return the error message\n            completion_response = f\"An error occurred: {str(e)}\"\n    \n        try:\n            # Make a call to the chat model\n            response_chat = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                max_tokens=remaining_tokens,\n                messages=create_chat_messages_for_api()\n            )\n            # Extract and clean the chat model response\n            chat_response = response_chat.choices[0].message.content.strip()\n            # Append the response to the conversation history\n            conversation_history.append({\"role\": \"assistant\", \"content\": chat_response})\n        except Exception as e:\n            # Handle exceptions and return the error message\n            chat_response = f\"An error occurred: {str(e)}\"\n    \n        # Decide which response to return\n        return decide_response(completion_response, chat_response)\n    \n    def create_completion_prompt(utterance):\n        \"\"\"\n        Creates a completion prompt with a predefined context for the OpenAI model.\n    \n        Args:\n            utterance (str): The user's input message.\n    \n        Returns:\n            str: The constructed prompt for the OpenAI model.\n        \"\"\"\n        # Predefined context for the AI model\n        introduction = (\n            \"You are an expert real estate agent well-versed in the Toronto and Ontario housing market. \"\n            \"You have comprehensive knowledge of local real estate laws, regulations, market trends, \"\n            \"property valuations, and lending practices. You provide detailed, accurate, and up-to-date information. \"\n            \"Your responses are professional and adhere to the current legal and market standards.\\n\\n\"\n        )\n        # Combine the context with the user's question\n        prompt = introduction + f\"Question: {utterance}\\nResponse:\"\n        return prompt\n    \n    def create_chat_messages_for_api():\n        \"\"\"\n        Formats the conversation history for the chat model API call.\n    \n        Returns:\n            list: A list of messages formatted for the chat model, excluding 'category' and 'word_freq'.\n        \"\"\"\n        formatted_history = []\n        for message in conversation_history:\n            formatted_message = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\n            formatted_history.append(formatted_message)\n        \n        return formatted_history\n    \n    def decide_response(completion_response, chat_response):\n        \"\"\"\n        Decides which response to use based on relevance and redundancy checks.\n    \n        Args:\n            completion_response (str): The response from the completion model.\n            chat_response (str): The response from the chat model.\n    \n        Returns:\n            str: The chosen response after evaluation.\n        \"\"\"\n        # Evaluate and return the most appropriate response\n        if is_response_relevant(completion_response) and not is_response_relevant(chat_response):\n            return completion_response\n        elif is_response_relevant(chat_response) and not is_response_relevant(completion_response):\n            return chat_response\n        elif is_response_redundant(completion_response, chat_response):\n            return completion_response\n        else:\n            return f\"Response 1: {completion_response}\\n\\nResponse 2: {chat_response}\"\n    \n    def is_response_relevant(response):\n        \"\"\"\n        Checks if the given response is relevant based on predefined criteria.\n    \n        Args:\n            response (str): The response to evaluate.\n    \n        Returns:\n            bool: True if the response is relevant, False otherwise.\n        \"\"\"\n        important_keywords = set([\"real estate\", \"market\", \"property\", \"Toronto\", \"Ontario\", \"laws\", \"regulations\", \"lending\"])\n        response_lower = response.lower()\n        for keyword in important_keywords:\n            if keyword in response_lower:\n                return True\n        min_length, max_length = 20, 300\n        if len(response) < min_length or len(response) > max_length:\n            return False\n        return True\n    \n    def is_response_redundant(response1, response2):\n        \"\"\"\n        Checks if two responses are redundant to each other.\n    \n        Args:\n            response1 (str): The first response.\n            response2 (str): The second response.\n    \n        Returns:\n            bool: True if the responses are redundant, False otherwise.\n        \"\"\"\n        words1 = set(response1.lower().split())\n        words2 = set(response2.lower().split())\n        common_words = words1.intersection(words2)\n        threshold = 0.5\n        redundancy_ratio = len(common_words) / min(len(words1), len(words2))\n        return redundancy_ratio > threshold`;\n  const style = {\n    container: {\n      padding: theme.spacing(3),\n      color: theme.palette.common.white,\n      backgroundColor: theme.palette.background.default,\n      minHeight: '100vh',\n      display: 'flex',\n      flexDirection: 'column',\n      alignItems: 'center',\n      justifyContent: 'center',\n      maxWidth: '600px',\n      // Set max width to 600px\n      marginLeft: 'auto',\n      // Center the container\n      marginRight: 'auto'\n    },\n    header: {\n      marginBottom: theme.spacing(2)\n    },\n    paragraph: {\n      marginBottom: theme.spacing(1),\n      textAlign: 'left' // Align text to the left\n    },\n    featureBox: {\n      marginTop: theme.spacing(4),\n      textAlign: 'left'\n    },\n    featureHeading: {\n      marginBottom: theme.spacing(1)\n    },\n    motivationBox: {\n      marginTop: theme.spacing(4),\n      textAlign: 'left'\n    },\n    codeBox: {\n      marginTop: theme.spacing(4),\n      backgroundColor: '#1e1e1e',\n      padding: theme.spacing(2),\n      borderRadius: theme.shape.borderRadius,\n      boxShadow: theme.shadows[1],\n      overflowX: 'auto',\n      color: '#f8f8f2' // Adjust the text color if needed\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(Box, {\n    sx: style.container,\n    children: [/*#__PURE__*/_jsxDEV(Typography, {\n      variant: \"h2\",\n      sx: style.header,\n      children: \"RealEstate AI Bot\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 278,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Typography, {\n      variant: \"body1\",\n      sx: style.paragraph,\n      children: \"This script defines the core functionality of a Real Estate Assistant Discord Bot. It integrates with OpenAI's GPT models to process user inquiries related to the real estate market, focusing on the Toronto and Ontario regions. The bot maintains a conversation history for context management, analyzes word frequency vectors, classifies utterances for emotional tone or speech act, and uses two different OpenAI API calls (completion and chat models) to generate informative and relevant responses.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 280,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Typography, {\n      variant: \"body1\",\n      sx: style.paragraph,\n      children: \"The script handles the construction of prompts for the OpenAI API, manages conversation history, analyzes word frequency, classifies utterances, determines the relevance and redundancy of responses, and decides the final response to be sent to the user. It is designed to be integrated with a Discord bot client for interaction in a Discord server environment.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 284,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      sx: style.featureBox,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"h4\",\n        sx: style.featureHeading,\n        children: \"Key Features:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 289,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"ul\", {\n        children: [/*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Utilizes OpenAI's powerful language models to answer real estate-related queries.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 291,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 291,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Analyzes word frequency vectors for better understanding of queries.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 292,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 292,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Classifies utterances based on emotional tone or speech act.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 293,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 293,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Maintains conversation context for more coherent and relevant interactions.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 294,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 294,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Employs two distinct models (completion and chat) for varied response generation.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 295,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 295,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Implements relevance and redundancy checks to optimize response quality.\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 296,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 296,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 290,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 288,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      sx: style.motivationBox,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"h4\",\n        sx: style.featureHeading,\n        children: \"Project Motivation:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 301,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"body1\",\n        children: \"This bot was created as an experiment to see if it's possible to replace the need for a traditional real estate agent with a bot trained on the right data. The goal is to provide instant, accurate, and personalized real estate advice using advanced AI technology.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 302,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 300,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      sx: style.motivationBox,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"h4\",\n        sx: style.featureHeading,\n        children: \"Discord Integration: Streamlining Development\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 308,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"body1\",\n        children: \"To enhance the development of the RealEstate AI Bot, I integrated it with Discord. This decision significantly accelerated the initial setup by eliminating the need to create a custom GUI. Utilizing Discord's existing chat interface allowed for immediate and efficient interaction with the bot, saving considerable time and focusing on its core functionalities.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 309,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 307,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      sx: style.featureBox,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"h4\",\n        sx: style.featureHeading,\n        children: \"Dependencies:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 317,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"ul\", {\n        children: [/*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"OpenAI Python client library\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 319,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 319,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Python 3.6 or higher\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 320,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 320,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"Discord.py library for Discord bot integration\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 321,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 321,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"spaCy for NLP tasks\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 322,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 322,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: /*#__PURE__*/_jsxDEV(Typography, {\n            variant: \"body1\",\n            children: \"sklearn for machine learning tasks\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 323,\n            columnNumber: 25\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 323,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 318,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 316,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      sx: style.codeBox,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        variant: \"h4\",\n        sx: style.featureHeading,\n        children: \"Python Code:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 328,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(SyntaxHighlighter, {\n        language: \"python\",\n        style: customDarkTheme,\n        children: pythonCode\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 329,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 327,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 277,\n    columnNumber: 9\n  }, this);\n};\n_s(RealEstateBot, \"juHf+cd7fzq7HP7pR78ZTOcoxCg=\", false, function () {\n  return [useNavigate, useTheme];\n});\n_c = RealEstateBot;\nexport default RealEstateBot;\nvar _c;\n$RefreshReg$(_c, \"RealEstateBot\");","map":{"version":3,"names":["React","Box","Typography","useTheme","useNavigate","Prism","SyntaxHighlighter","dark","jsxDEV","_jsxDEV","RealEstateBot","_s","navigate","theme","customDarkTheme","color","background","fontSize","textAlign","wordSpacing","wordBreak","wordWrap","lineHeight","tabSize","hyphens","pythonCode","style","container","padding","spacing","palette","common","white","backgroundColor","default","minHeight","display","flexDirection","alignItems","justifyContent","maxWidth","marginLeft","marginRight","header","marginBottom","paragraph","featureBox","marginTop","featureHeading","motivationBox","codeBox","borderRadius","shape","boxShadow","shadows","overflowX","sx","children","variant","fileName","_jsxFileName","lineNumber","columnNumber","language","_c","$RefreshReg$"],"sources":["A:/Projects/AnthonyMercadante.github.io/src/components/RealEstateBot/RealEstateBot.tsx"],"sourcesContent":["import React from 'react';\r\nimport { Box, Button, Typography, useTheme } from '@mui/material';\r\nimport { useNavigate } from 'react-router-dom';\r\nimport { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';\r\nimport { dark } from 'react-syntax-highlighter/dist/esm/styles/prism';\r\n\r\n\r\n\r\nconst RealEstateBot = () => {\r\n    const navigate = useNavigate();\r\n    const theme = useTheme();\r\n\r\n    const customDarkTheme = {\r\n        ...dark,\r\n        // Override specific styles. Example:\r\n        'code[class*=\"language-\"]': {\r\n            ...dark['code[class*=\"language-\"]'],\r\n            color: '#f8f8f2',\r\n            background: 'none',\r\n            fontSize: '1em',\r\n            textAlign: 'left',\r\n            wordSpacing: 'normal',\r\n            wordBreak: 'normal',\r\n            wordWrap: 'normal',\r\n            lineHeight: '1.5',\r\n            tabSize: '4',\r\n            hyphens: 'none'\r\n        },\r\n        // Add additional customizations as needed\r\n    };\r\n\r\n    const pythonCode = `Created by Anthony Mercadante\r\n    Date: November 2023\r\n    \"\"\"\r\n    \r\n    from openai import OpenAI\r\n    import os\r\n    import spacy\r\n    from sklearn.feature_extraction.text import CountVectorizer\r\n    \r\n    # Initialize the OpenAI client with the API key from environment variables\r\n    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\r\n    \r\n    # Load the spaCy language model\r\n    nlp = spacy.load(\"en_core_web_sm\")\r\n    \r\n    # Global variable to maintain the conversation history\r\n    conversation_history = []\r\n    \r\n    def analyze_word_frequency(utterance):\r\n        \"\"\"\r\n        Analyzes the frequency of words in the given utterance.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            dict: A dictionary of word frequencies.\r\n        \"\"\"\r\n        doc = nlp(utterance)\r\n        vectorizer = CountVectorizer()\r\n        vectorized_words = vectorizer.fit_transform([utterance])\r\n        word_freq = dict(zip(vectorizer.get_feature_names_out(), vectorized_words.toarray().tolist()[0]))\r\n        return word_freq\r\n    \r\n    def classify_utterance(utterance):\r\n        \"\"\"\r\n        Classifies the given utterance into categories like emotional tone or speech act.\r\n        Placeholder function - actual implementation required.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            str: The classified category of the utterance.\r\n        \"\"\"\r\n        # Placeholder: Implement a classifier or use an existing model\r\n        return \"general_inquiry\"\r\n    \r\n    def ask_openai(utterance):\r\n        \"\"\"\r\n        Processes the given user utterance and generates a response using OpenAI's API.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            str: The generated response from the bot.\r\n        \"\"\"\r\n        global conversation_history\r\n        # Analyze word frequency and classify utterance\r\n        word_freq = analyze_word_frequency(utterance)\r\n        utterance_category = classify_utterance(utterance)\r\n    \r\n        # Append the user's utterance and additional info to the conversation history\r\n        conversation_history.append({\"role\": \"user\", \"content\": utterance, \"word_freq\": word_freq, \"category\": utterance_category})\r\n    \r\n        try:\r\n            # Construct a prompt for the completion model\r\n            prompt = create_completion_prompt(utterance)\r\n            # Set a maximum token limit for the prompt\r\n            max_prompt_tokens = 500\r\n            prompt_length = len(prompt.split())\r\n            remaining_tokens = max(20, max_prompt_tokens - prompt_length)\r\n    \r\n            # Make a call to the completion model\r\n            response_completion = client.completions.create(\r\n                model=\"text-davinci-003\",\r\n                prompt=prompt,\r\n                temperature=0.7,\r\n                max_tokens=remaining_tokens\r\n            )\r\n            # Extract and clean the response\r\n            completion_response = response_completion.choices[0].text.strip()\r\n            # Append the response to the conversation history\r\n            conversation_history.append({\"role\": \"assistant\", \"content\": completion_response})\r\n        except Exception as e:\r\n            # Handle exceptions and return the error message\r\n            completion_response = f\"An error occurred: {str(e)}\"\r\n    \r\n        try:\r\n            # Make a call to the chat model\r\n            response_chat = client.chat.completions.create(\r\n                model=\"gpt-3.5-turbo\",\r\n                max_tokens=remaining_tokens,\r\n                messages=create_chat_messages_for_api()\r\n            )\r\n            # Extract and clean the chat model response\r\n            chat_response = response_chat.choices[0].message.content.strip()\r\n            # Append the response to the conversation history\r\n            conversation_history.append({\"role\": \"assistant\", \"content\": chat_response})\r\n        except Exception as e:\r\n            # Handle exceptions and return the error message\r\n            chat_response = f\"An error occurred: {str(e)}\"\r\n    \r\n        # Decide which response to return\r\n        return decide_response(completion_response, chat_response)\r\n    \r\n    def create_completion_prompt(utterance):\r\n        \"\"\"\r\n        Creates a completion prompt with a predefined context for the OpenAI model.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            str: The constructed prompt for the OpenAI model.\r\n        \"\"\"\r\n        # Predefined context for the AI model\r\n        introduction = (\r\n            \"You are an expert real estate agent well-versed in the Toronto and Ontario housing market. \"\r\n            \"You have comprehensive knowledge of local real estate laws, regulations, market trends, \"\r\n            \"property valuations, and lending practices. You provide detailed, accurate, and up-to-date information. \"\r\n            \"Your responses are professional and adhere to the current legal and market standards.\\n\\n\"\r\n        )\r\n        # Combine the context with the user's question\r\n        prompt = introduction + f\"Question: {utterance}\\nResponse:\"\r\n        return prompt\r\n    \r\n    def create_chat_messages_for_api():\r\n        \"\"\"\r\n        Formats the conversation history for the chat model API call.\r\n    \r\n        Returns:\r\n            list: A list of messages formatted for the chat model, excluding 'category' and 'word_freq'.\r\n        \"\"\"\r\n        formatted_history = []\r\n        for message in conversation_history:\r\n            formatted_message = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\r\n            formatted_history.append(formatted_message)\r\n        \r\n        return formatted_history\r\n    \r\n    def decide_response(completion_response, chat_response):\r\n        \"\"\"\r\n        Decides which response to use based on relevance and redundancy checks.\r\n    \r\n        Args:\r\n            completion_response (str): The response from the completion model.\r\n            chat_response (str): The response from the chat model.\r\n    \r\n        Returns:\r\n            str: The chosen response after evaluation.\r\n        \"\"\"\r\n        # Evaluate and return the most appropriate response\r\n        if is_response_relevant(completion_response) and not is_response_relevant(chat_response):\r\n            return completion_response\r\n        elif is_response_relevant(chat_response) and not is_response_relevant(completion_response):\r\n            return chat_response\r\n        elif is_response_redundant(completion_response, chat_response):\r\n            return completion_response\r\n        else:\r\n            return f\"Response 1: {completion_response}\\n\\nResponse 2: {chat_response}\"\r\n    \r\n    def is_response_relevant(response):\r\n        \"\"\"\r\n        Checks if the given response is relevant based on predefined criteria.\r\n    \r\n        Args:\r\n            response (str): The response to evaluate.\r\n    \r\n        Returns:\r\n            bool: True if the response is relevant, False otherwise.\r\n        \"\"\"\r\n        important_keywords = set([\"real estate\", \"market\", \"property\", \"Toronto\", \"Ontario\", \"laws\", \"regulations\", \"lending\"])\r\n        response_lower = response.lower()\r\n        for keyword in important_keywords:\r\n            if keyword in response_lower:\r\n                return True\r\n        min_length, max_length = 20, 300\r\n        if len(response) < min_length or len(response) > max_length:\r\n            return False\r\n        return True\r\n    \r\n    def is_response_redundant(response1, response2):\r\n        \"\"\"\r\n        Checks if two responses are redundant to each other.\r\n    \r\n        Args:\r\n            response1 (str): The first response.\r\n            response2 (str): The second response.\r\n    \r\n        Returns:\r\n            bool: True if the responses are redundant, False otherwise.\r\n        \"\"\"\r\n        words1 = set(response1.lower().split())\r\n        words2 = set(response2.lower().split())\r\n        common_words = words1.intersection(words2)\r\n        threshold = 0.5\r\n        redundancy_ratio = len(common_words) / min(len(words1), len(words2))\r\n        return redundancy_ratio > threshold`;\r\n\r\n    const style = {\r\n        container: {\r\n            padding: theme.spacing(3),\r\n            color: theme.palette.common.white,\r\n            backgroundColor: theme.palette.background.default,\r\n            minHeight: '100vh',\r\n            display: 'flex',\r\n            flexDirection: 'column',\r\n            alignItems: 'center',\r\n            justifyContent: 'center',\r\n            maxWidth: '600px', // Set max width to 600px\r\n            marginLeft: 'auto', // Center the container\r\n            marginRight: 'auto',\r\n        },\r\n        header: {\r\n            marginBottom: theme.spacing(2),\r\n        },\r\n        paragraph: {\r\n            marginBottom: theme.spacing(1),\r\n            textAlign: 'left', // Align text to the left\r\n        },\r\n        featureBox: {\r\n            marginTop: theme.spacing(4),\r\n            textAlign: 'left',\r\n        },\r\n        featureHeading: {\r\n            marginBottom: theme.spacing(1),\r\n        },\r\n        motivationBox: {\r\n            marginTop: theme.spacing(4),\r\n            textAlign: 'left',\r\n        },\r\n        codeBox: {\r\n            marginTop: theme.spacing(4),\r\n            backgroundColor: '#1e1e1e', \r\n            padding: theme.spacing(2),\r\n            borderRadius: theme.shape.borderRadius,\r\n            boxShadow: theme.shadows[1],\r\n            overflowX: 'auto',\r\n            color: '#f8f8f2' // Adjust the text color if needed\r\n        },\r\n    };\r\n\r\n    return (\r\n        <Box sx={style.container}>\r\n            <Typography variant=\"h2\" sx={style.header}>RealEstate AI Bot</Typography>\r\n            \r\n            <Typography variant=\"body1\" sx={style.paragraph}>\r\n                This script defines the core functionality of a Real Estate Assistant Discord Bot. It integrates with OpenAI's GPT models to process user inquiries related to the real estate market, focusing on the Toronto and Ontario regions. The bot maintains a conversation history for context management, analyzes word frequency vectors, classifies utterances for emotional tone or speech act, and uses two different OpenAI API calls (completion and chat models) to generate informative and relevant responses.\r\n            </Typography>\r\n            \r\n            <Typography variant=\"body1\" sx={style.paragraph}>\r\n                The script handles the construction of prompts for the OpenAI API, manages conversation history, analyzes word frequency, classifies utterances, determines the relevance and redundancy of responses, and decides the final response to be sent to the user. It is designed to be integrated with a Discord bot client for interaction in a Discord server environment.\r\n            </Typography>\r\n\r\n            <Box sx={style.featureBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Key Features:</Typography>\r\n                <ul>\r\n                    <li><Typography variant=\"body1\">Utilizes OpenAI's powerful language models to answer real estate-related queries.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Analyzes word frequency vectors for better understanding of queries.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Classifies utterances based on emotional tone or speech act.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Maintains conversation context for more coherent and relevant interactions.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Employs two distinct models (completion and chat) for varied response generation.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Implements relevance and redundancy checks to optimize response quality.</Typography></li>\r\n                </ul>\r\n            </Box>\r\n\r\n            <Box sx={style.motivationBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Project Motivation:</Typography>\r\n                <Typography variant=\"body1\">\r\n                    This bot was created as an experiment to see if it's possible to replace the need for a traditional real estate agent with a bot trained on the right data. The goal is to provide instant, accurate, and personalized real estate advice using advanced AI technology.\r\n                </Typography>\r\n            </Box>\r\n\r\n            <Box sx={style.motivationBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Discord Integration: Streamlining Development</Typography>\r\n                <Typography variant=\"body1\">\r\n                To enhance the development of the RealEstate AI Bot, I integrated it with Discord. This decision significantly accelerated the initial setup by eliminating the need to create a custom GUI. Utilizing Discord's existing chat interface allowed for immediate and efficient interaction with the bot, saving considerable time and focusing on its core functionalities.\r\n                </Typography>\r\n            </Box>\r\n\r\n\r\n\r\n            <Box sx={style.featureBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Dependencies:</Typography>\r\n                <ul>\r\n                    <li><Typography variant=\"body1\">OpenAI Python client library</Typography></li>\r\n                    <li><Typography variant=\"body1\">Python 3.6 or higher</Typography></li>\r\n                    <li><Typography variant=\"body1\">Discord.py library for Discord bot integration</Typography></li>\r\n                    <li><Typography variant=\"body1\">spaCy for NLP tasks</Typography></li>\r\n                    <li><Typography variant=\"body1\">sklearn for machine learning tasks</Typography></li>\r\n                </ul>\r\n            </Box>\r\n\r\n            <Box sx={style.codeBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Python Code:</Typography>\r\n                <SyntaxHighlighter language=\"python\" style={customDarkTheme}>\r\n                    {pythonCode}\r\n                </SyntaxHighlighter>\r\n            </Box>\r\n        </Box>\r\n    );\r\n};\r\n\r\nexport default RealEstateBot;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,SAASC,GAAG,EAAUC,UAAU,EAAEC,QAAQ,QAAQ,eAAe;AACjE,SAASC,WAAW,QAAQ,kBAAkB;AAC9C,SAASC,KAAK,IAAIC,iBAAiB,QAAQ,0BAA0B;AACrE,SAASC,IAAI,QAAQ,gDAAgD;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAItE,MAAMC,aAAa,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACxB,MAAMC,QAAQ,GAAGR,WAAW,CAAC,CAAC;EAC9B,MAAMS,KAAK,GAAGV,QAAQ,CAAC,CAAC;EAExB,MAAMW,eAAe,GAAG;IACpB,GAAGP,IAAI;IACP;IACA,0BAA0B,EAAE;MACxB,GAAGA,IAAI,CAAC,0BAA0B,CAAC;MACnCQ,KAAK,EAAE,SAAS;MAChBC,UAAU,EAAE,MAAM;MAClBC,QAAQ,EAAE,KAAK;MACfC,SAAS,EAAE,MAAM;MACjBC,WAAW,EAAE,QAAQ;MACrBC,SAAS,EAAE,QAAQ;MACnBC,QAAQ,EAAE,QAAQ;MAClBC,UAAU,EAAE,KAAK;MACjBC,OAAO,EAAE,GAAG;MACZC,OAAO,EAAE;IACb;IACA;EACJ,CAAC;EAED,MAAMC,UAAU,GAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;EAExC,MAAMC,KAAK,GAAG;IACVC,SAAS,EAAE;MACPC,OAAO,EAAEf,KAAK,CAACgB,OAAO,CAAC,CAAC,CAAC;MACzBd,KAAK,EAAEF,KAAK,CAACiB,OAAO,CAACC,MAAM,CAACC,KAAK;MACjCC,eAAe,EAAEpB,KAAK,CAACiB,OAAO,CAACd,UAAU,CAACkB,OAAO;MACjDC,SAAS,EAAE,OAAO;MAClBC,OAAO,EAAE,MAAM;MACfC,aAAa,EAAE,QAAQ;MACvBC,UAAU,EAAE,QAAQ;MACpBC,cAAc,EAAE,QAAQ;MACxBC,QAAQ,EAAE,OAAO;MAAE;MACnBC,UAAU,EAAE,MAAM;MAAE;MACpBC,WAAW,EAAE;IACjB,CAAC;IACDC,MAAM,EAAE;MACJC,YAAY,EAAE/B,KAAK,CAACgB,OAAO,CAAC,CAAC;IACjC,CAAC;IACDgB,SAAS,EAAE;MACPD,YAAY,EAAE/B,KAAK,CAACgB,OAAO,CAAC,CAAC,CAAC;MAC9BX,SAAS,EAAE,MAAM,CAAE;IACvB,CAAC;IACD4B,UAAU,EAAE;MACRC,SAAS,EAAElC,KAAK,CAACgB,OAAO,CAAC,CAAC,CAAC;MAC3BX,SAAS,EAAE;IACf,CAAC;IACD8B,cAAc,EAAE;MACZJ,YAAY,EAAE/B,KAAK,CAACgB,OAAO,CAAC,CAAC;IACjC,CAAC;IACDoB,aAAa,EAAE;MACXF,SAAS,EAAElC,KAAK,CAACgB,OAAO,CAAC,CAAC,CAAC;MAC3BX,SAAS,EAAE;IACf,CAAC;IACDgC,OAAO,EAAE;MACLH,SAAS,EAAElC,KAAK,CAACgB,OAAO,CAAC,CAAC,CAAC;MAC3BI,eAAe,EAAE,SAAS;MAC1BL,OAAO,EAAEf,KAAK,CAACgB,OAAO,CAAC,CAAC,CAAC;MACzBsB,YAAY,EAAEtC,KAAK,CAACuC,KAAK,CAACD,YAAY;MACtCE,SAAS,EAAExC,KAAK,CAACyC,OAAO,CAAC,CAAC,CAAC;MAC3BC,SAAS,EAAE,MAAM;MACjBxC,KAAK,EAAE,SAAS,CAAC;IACrB;EACJ,CAAC;EAED,oBACIN,OAAA,CAACR,GAAG;IAACuD,EAAE,EAAE9B,KAAK,CAACC,SAAU;IAAA8B,QAAA,gBACrBhD,OAAA,CAACP,UAAU;MAACwD,OAAO,EAAC,IAAI;MAACF,EAAE,EAAE9B,KAAK,CAACiB,MAAO;MAAAc,QAAA,EAAC;IAAiB;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAY,CAAC,eAEzErD,OAAA,CAACP,UAAU;MAACwD,OAAO,EAAC,OAAO;MAACF,EAAE,EAAE9B,KAAK,CAACmB,SAAU;MAAAY,QAAA,EAAC;IAEjD;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAY,CAAC,eAEbrD,OAAA,CAACP,UAAU;MAACwD,OAAO,EAAC,OAAO;MAACF,EAAE,EAAE9B,KAAK,CAACmB,SAAU;MAAAY,QAAA,EAAC;IAEjD;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAY,CAAC,eAEbrD,OAAA,CAACR,GAAG;MAACuD,EAAE,EAAE9B,KAAK,CAACoB,UAAW;MAAAW,QAAA,gBACtBhD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,IAAI;QAACF,EAAE,EAAE9B,KAAK,CAACsB,cAAe;QAAAS,QAAA,EAAC;MAAa;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC,eAC7ErD,OAAA;QAAAgD,QAAA,gBACIhD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAiF;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACnIrD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAoE;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACtHrD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAA4D;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC9GrD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAA2E;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC7HrD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAiF;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACnIrD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAwE;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC1H,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACJ,CAAC,eAENrD,OAAA,CAACR,GAAG;MAACuD,EAAE,EAAE9B,KAAK,CAACuB,aAAc;MAAAQ,QAAA,gBACzBhD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,IAAI;QAACF,EAAE,EAAE9B,KAAK,CAACsB,cAAe;QAAAS,QAAA,EAAC;MAAmB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC,eACnFrD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,OAAO;QAAAD,QAAA,EAAC;MAE5B;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACZ,CAAC,eAENrD,OAAA,CAACR,GAAG;MAACuD,EAAE,EAAE9B,KAAK,CAACuB,aAAc;MAAAQ,QAAA,gBACzBhD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,IAAI;QAACF,EAAE,EAAE9B,KAAK,CAACsB,cAAe;QAAAS,QAAA,EAAC;MAA6C;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC,eAC7GrD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,OAAO;QAAAD,QAAA,EAAC;MAE5B;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACZ,CAAC,eAINrD,OAAA,CAACR,GAAG;MAACuD,EAAE,EAAE9B,KAAK,CAACoB,UAAW;MAAAW,QAAA,gBACtBhD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,IAAI;QAACF,EAAE,EAAE9B,KAAK,CAACsB,cAAe;QAAAS,QAAA,EAAC;MAAa;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC,eAC7ErD,OAAA;QAAAgD,QAAA,gBACIhD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAA4B;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC9ErD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAoB;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACtErD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAA8C;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAChGrD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAmB;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACrErD,OAAA;UAAAgD,QAAA,eAAIhD,OAAA,CAACP,UAAU;YAACwD,OAAO,EAAC,OAAO;YAAAD,QAAA,EAAC;UAAkC;YAAAE,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAY;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACpF,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACJ,CAAC,eAENrD,OAAA,CAACR,GAAG;MAACuD,EAAE,EAAE9B,KAAK,CAACwB,OAAQ;MAAAO,QAAA,gBACnBhD,OAAA,CAACP,UAAU;QAACwD,OAAO,EAAC,IAAI;QAACF,EAAE,EAAE9B,KAAK,CAACsB,cAAe;QAAAS,QAAA,EAAC;MAAY;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAY,CAAC,eAC5ErD,OAAA,CAACH,iBAAiB;QAACyD,QAAQ,EAAC,QAAQ;QAACrC,KAAK,EAAEZ,eAAgB;QAAA2C,QAAA,EACvDhC;MAAU;QAAAkC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACnB,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACL,CAAC;AAEd,CAAC;AAACnD,EAAA,CAtUID,aAAa;EAAA,QACEN,WAAW,EACdD,QAAQ;AAAA;AAAA6D,EAAA,GAFpBtD,aAAa;AAwUnB,eAAeA,aAAa;AAAC,IAAAsD,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}