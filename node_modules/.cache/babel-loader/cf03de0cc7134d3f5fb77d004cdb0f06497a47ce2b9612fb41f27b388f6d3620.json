{"ast":null,"code":"import React from'react';import{Box,Typography,useTheme}from'@mui/material';import{useNavigate}from'react-router-dom';import{Prism as SyntaxHighlighter}from'react-syntax-highlighter';import{dark}from'react-syntax-highlighter/dist/esm/styles/prism';import{jsx as _jsx}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";const RealEstateBot=()=>{const navigate=useNavigate();const theme=useTheme();const pythonCode=\"\\n    \\\"\\\"\\\"\\n    core_bot.py\\n    Created by Anthony Mercadante\\n    Date: November 2023\\n    \\\"\\\"\\\"\\n    \\n    from openai import OpenAI\\n    import os\\n    import spacy\\n    from sklearn.feature_extraction.text import CountVectorizer\\n    \\n    # Initialize the OpenAI client with the API key from environment variables\\n    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\\n    \\n    # Load the spaCy language model\\n    nlp = spacy.load(\\\"en_core_web_sm\\\")\\n    \\n    # Global variable to maintain the conversation history\\n    conversation_history = []\\n    \\n    def analyze_word_frequency(utterance):\\n        \\\"\\\"\\\"\\n        Analyzes the frequency of words in the given utterance.\\n    \\n        Args:\\n            utterance (str): The user's input message.\\n    \\n        Returns:\\n            dict: A dictionary of word frequencies.\\n        \\\"\\\"\\\"\\n        doc = nlp(utterance)\\n        vectorizer = CountVectorizer()\\n        vectorized_words = vectorizer.fit_transform([utterance])\\n        word_freq = dict(zip(vectorizer.get_feature_names_out(), vectorized_words.toarray().tolist()[0]))\\n        return word_freq\\n    \\n    def classify_utterance(utterance):\\n        \\\"\\\"\\\"\\n        Classifies the given utterance into categories like emotional tone or speech act.\\n        Placeholder function - actual implementation required.\\n    \\n        Args:\\n            utterance (str): The user's input message.\\n    \\n        Returns:\\n            str: The classified category of the utterance.\\n        \\\"\\\"\\\"\\n        # Placeholder: Implement a classifier or use an existing model\\n        return \\\"general_inquiry\\\"\\n    \\n    def ask_openai(utterance):\\n        \\\"\\\"\\\"\\n        Processes the given user utterance and generates a response using OpenAI's API.\\n    \\n        Args:\\n            utterance (str): The user's input message.\\n    \\n        Returns:\\n            str: The generated response from the bot.\\n        \\\"\\\"\\\"\\n        global conversation_history\\n        # Analyze word frequency and classify utterance\\n        word_freq = analyze_word_frequency(utterance)\\n        utterance_category = classify_utterance(utterance)\\n    \\n        # Append the user's utterance and additional info to the conversation history\\n        conversation_history.append({\\\"role\\\": \\\"user\\\", \\\"content\\\": utterance, \\\"word_freq\\\": word_freq, \\\"category\\\": utterance_category})\\n    \\n        try:\\n            # Construct a prompt for the completion model\\n            prompt = create_completion_prompt(utterance)\\n            # Set a maximum token limit for the prompt\\n            max_prompt_tokens = 500\\n            prompt_length = len(prompt.split())\\n            remaining_tokens = max(20, max_prompt_tokens - prompt_length)\\n    \\n            # Make a call to the completion model\\n            response_completion = client.completions.create(\\n                model=\\\"text-davinci-003\\\",\\n                prompt=prompt,\\n                temperature=0.7,\\n                max_tokens=remaining_tokens\\n            )\\n            # Extract and clean the response\\n            completion_response = response_completion.choices[0].text.strip()\\n            # Append the response to the conversation history\\n            conversation_history.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": completion_response})\\n        except Exception as e:\\n            # Handle exceptions and return the error message\\n            completion_response = f\\\"An error occurred: {str(e)}\\\"\\n    \\n        try:\\n            # Make a call to the chat model\\n            response_chat = client.chat.completions.create(\\n                model=\\\"gpt-3.5-turbo\\\",\\n                max_tokens=remaining_tokens,\\n                messages=create_chat_messages_for_api()\\n            )\\n            # Extract and clean the chat model response\\n            chat_response = response_chat.choices[0].message.content.strip()\\n            # Append the response to the conversation history\\n            conversation_history.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": chat_response})\\n        except Exception as e:\\n            # Handle exceptions and return the error message\\n            chat_response = f\\\"An error occurred: {str(e)}\\\"\\n    \\n        # Decide which response to return\\n        return decide_response(completion_response, chat_response)\\n    \\n    def create_completion_prompt(utterance):\\n        \\\"\\\"\\\"\\n        Creates a completion prompt with a predefined context for the OpenAI model.\\n    \\n        Args:\\n            utterance (str): The user's input message.\\n    \\n        Returns:\\n            str: The constructed prompt for the OpenAI model.\\n        \\\"\\\"\\\"\\n        # Predefined context for the AI model\\n        introduction = (\\n            \\\"You are an expert real estate agent well-versed in the Toronto and Ontario housing market. \\\"\\n            \\\"You have comprehensive knowledge of local real estate laws, regulations, market trends, \\\"\\n            \\\"property valuations, and lending practices. You provide detailed, accurate, and up-to-date information. \\\"\\n            \\\"Your responses are professional and adhere to the current legal and market standards.\\\"\\n        )\\n        # Combine the context with the user's question\\n        prompt = introduction + f\\\"Question: {utterance}Response:\\\"\\n        return prompt\\n    \\n    def create_chat_messages_for_api():\\n        \\\"\\\"\\\"\\n        Formats the conversation history for the chat model API call.\\n    \\n        Returns:\\n            list: A list of messages formatted for the chat model, excluding 'category' and 'word_freq'.\\n        \\\"\\\"\\\"\\n        formatted_history = []\\n        for message in conversation_history:\\n            formatted_message = {\\\"role\\\": message[\\\"role\\\"], \\\"content\\\": message[\\\"content\\\"]}\\n            formatted_history.append(formatted_message)\\n        \\n        return formatted_history\\n    \\n    def decide_response(completion_response, chat_response):\\n        \\\"\\\"\\\"\\n        Decides which response to use based on relevance and redundancy checks.\\n    \\n        Args:\\n            completion_response (str): The response from the completion model.\\n            chat_response (str): The response from the chat model.\\n    \\n        Returns:\\n            str: The chosen response after evaluation.\\n        \\\"\\\"\\\"\\n        # Evaluate and return the most appropriate response\\n        if is_response_relevant(completion_response) and not is_response_relevant(chat_response):\\n            return completion_response\\n        elif is_response_relevant(chat_response) and not is_response_relevant(completion_response):\\n            return chat_response\\n        elif is_response_redundant(completion_response, chat_response):\\n            return completion_response\\n        else:\\n            return f\\\"Response 1: {completion_response}Response 2: {chat_response}\\\"\\n    \\n    def is_response_relevant(response):\\n        \\\"\\\"\\\"\\n        Checks if the given response is relevant based on predefined criteria.\\n    \\n        Args:\\n            response (str): The response to evaluate.\\n    \\n        Returns:\\n            bool: True if the response is relevant, False otherwise.\\n        \\\"\\\"\\\"\\n        important_keywords = set([\\\"real estate\\\", \\\"market\\\", \\\"property\\\", \\\"Toronto\\\", \\\"Ontario\\\", \\\"laws\\\", \\\"regulations\\\", \\\"lending\\\"])\\n        response_lower = response.lower()\\n        for keyword in important_keywords:\\n            if keyword in response_lower:\\n                return True\\n        min_length, max_length = 20, 300\\n        if len(response) < min_length or len(response) > max_length:\\n            return False\\n        return True\\n    \\n    def is_response_redundant(response1, response2):\\n        \\\"\\\"\\\"\\n        Checks if two responses are redundant to each other.\\n    \\n        Args:\\n            response1 (str): The first response.\\n            response2 (str): The second response.\\n    \\n        Returns:\\n            bool: True if the responses are redundant, False otherwise.\\n        \\\"\\\"\\\"\\n        words1 = set(response1.lower().split())\\n        words2 = set(response2.lower().split())\\n        common_words = words1.intersection(words2)\\n        threshold = 0.5\\n        redundancy_ratio = len(common_words) / min(len(words1), len(words2))\\n        return redundancy_ratio > threshold\";const style={container:{padding:theme.spacing(3),color:theme.palette.common.white,backgroundColor:theme.palette.background.default,minHeight:'100vh',display:'flex',flexDirection:'column',alignItems:'center',justifyContent:'center',maxWidth:'600px',// Set max width to 600px\nmarginLeft:'auto',// Center the container\nmarginRight:'auto',[theme.breakpoints.down('md')]:{// Adjust for medium and smaller devices\nmaxWidth:'100%',padding:theme.spacing(2)}},header:{marginBottom:theme.spacing(2)},paragraph:{marginBottom:theme.spacing(1),textAlign:'left'// Align text to the left\n},featureBox:{marginTop:theme.spacing(4),textAlign:'left'},featureHeading:{marginBottom:theme.spacing(1)},motivationBox:{marginTop:theme.spacing(4),textAlign:'left'},codeBox:{marginTop:theme.spacing(4),backgroundColor:'#1e1e1e',padding:theme.spacing(2),borderRadius:theme.shape.borderRadius,boxShadow:theme.shadows[1],overflowX:'auto',color:'#f8f8f2',// Adjust the text color if needed\n[theme.breakpoints.down('sm')]:{// Adjust for small devices\nfontSize:'0.8em',// Smaller font size for small devices\nwidth:'100%'}}};return/*#__PURE__*/_jsxs(Box,{sx:style.container,children:[/*#__PURE__*/_jsx(Typography,{variant:\"h2\",sx:style.header,children:\"RealEstate AI Bot\"}),/*#__PURE__*/_jsx(Typography,{variant:\"body1\",sx:style.paragraph,children:\"This script is the backbone of a Real Estate Assistant Discord Bot, leveraging OpenAI's GPT models for handling real estate inquiries, particularly within the Toronto and Ontario markets. It's adept at maintaining conversation histories to ensure contextually aware interactions, while also utilizing advanced techniques like word frequency analysis and emotional tone classification to understand and respond to user queries effectively.\"}),/*#__PURE__*/_jsx(Typography,{variant:\"body1\",sx:style.paragraph,children:\"Furthermore, the script is intricately designed to craft detailed prompts for the OpenAI API, ensuring each response is tailored and relevant. Its sophisticated logic not only manages dialogue history but also evaluates the relevance and redundancy of potential responses. This seamless integration with a Discord bot client allows for dynamic interactions in a server environment, enhancing user engagement.\"}),/*#__PURE__*/_jsxs(Box,{sx:style.featureBox,children:[/*#__PURE__*/_jsx(Typography,{variant:\"h4\",sx:style.featureHeading,children:\"Key Features:\"}),/*#__PURE__*/_jsxs(\"ul\",{children:[/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Utilizes OpenAI's powerful language models to answer real estate-related queries.\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Analyzes word frequency vectors for better understanding of queries.\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Classifies utterances based on emotional tone or speech act.\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Maintains conversation context for more coherent and relevant interactions.\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Employs two distinct models (completion and chat) for varied response generation.\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Implements relevance and redundancy checks to optimize response quality.\"})})]})]}),/*#__PURE__*/_jsxs(Box,{sx:style.motivationBox,children:[/*#__PURE__*/_jsx(Typography,{variant:\"h4\",sx:style.featureHeading,children:\"Project Motivation:\"}),/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"This bot was created as an experiment to see if it's possible to replace the need for a traditional real estate agent with a bot trained on the right data. The goal is to provide instant, accurate, and personalized real estate advice using advanced AI technology.\"})]}),/*#__PURE__*/_jsxs(Box,{sx:style.motivationBox,children:[/*#__PURE__*/_jsx(Typography,{variant:\"h4\",sx:style.featureHeading,children:\"Discord Integration: Streamlining Development\"}),/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"To enhance the development of the RealEstate AI Bot, I integrated it with Discord. This decision significantly accelerated the initial setup by eliminating the need to create a custom GUI. Utilizing Discord's existing chat interface allowed for immediate and efficient interaction with the bot, saving considerable time and focusing on its core functionalities.\"})]}),/*#__PURE__*/_jsxs(Box,{sx:style.featureBox,children:[/*#__PURE__*/_jsx(Typography,{variant:\"h4\",sx:style.featureHeading,children:\"Dependencies:\"}),/*#__PURE__*/_jsxs(\"ul\",{children:[/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"OpenAI Python client library\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Python 3.6 or higher\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"Discord.py library for Discord bot integration\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"spaCy for NLP tasks\"})}),/*#__PURE__*/_jsx(\"li\",{children:/*#__PURE__*/_jsx(Typography,{variant:\"body1\",children:\"sklearn for machine learning tasks\"})})]})]}),/*#__PURE__*/_jsxs(Box,{sx:style.codeBox,children:[/*#__PURE__*/_jsx(Typography,{variant:\"h4\",sx:style.featureHeading,children:\"Python Code:\"}),/*#__PURE__*/_jsx(SyntaxHighlighter,{language:\"python\",style:dark,children:pythonCode})]})]});};export default RealEstateBot;","map":{"version":3,"names":["React","Box","Typography","useTheme","useNavigate","Prism","SyntaxHighlighter","dark","jsx","_jsx","jsxs","_jsxs","RealEstateBot","navigate","theme","pythonCode","style","container","padding","spacing","color","palette","common","white","backgroundColor","background","default","minHeight","display","flexDirection","alignItems","justifyContent","maxWidth","marginLeft","marginRight","breakpoints","down","header","marginBottom","paragraph","textAlign","featureBox","marginTop","featureHeading","motivationBox","codeBox","borderRadius","shape","boxShadow","shadows","overflowX","fontSize","width","sx","children","variant","language"],"sources":["A:/Projects/AnthonyMercadante.github.io/src/components/RealEstateBot/RealEstateBot.tsx"],"sourcesContent":["import React from 'react';\r\nimport { Box, Button, Typography, useTheme } from '@mui/material';\r\nimport { useNavigate } from 'react-router-dom';\r\nimport { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';\r\nimport { dark } from 'react-syntax-highlighter/dist/esm/styles/prism';\r\n\r\nconst RealEstateBot = () => {\r\n    const navigate = useNavigate();\r\n    const theme = useTheme();\r\n\r\n    const pythonCode = `\r\n    \"\"\"\r\n    core_bot.py\r\n    Created by Anthony Mercadante\r\n    Date: November 2023\r\n    \"\"\"\r\n    \r\n    from openai import OpenAI\r\n    import os\r\n    import spacy\r\n    from sklearn.feature_extraction.text import CountVectorizer\r\n    \r\n    # Initialize the OpenAI client with the API key from environment variables\r\n    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\r\n    \r\n    # Load the spaCy language model\r\n    nlp = spacy.load(\"en_core_web_sm\")\r\n    \r\n    # Global variable to maintain the conversation history\r\n    conversation_history = []\r\n    \r\n    def analyze_word_frequency(utterance):\r\n        \"\"\"\r\n        Analyzes the frequency of words in the given utterance.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            dict: A dictionary of word frequencies.\r\n        \"\"\"\r\n        doc = nlp(utterance)\r\n        vectorizer = CountVectorizer()\r\n        vectorized_words = vectorizer.fit_transform([utterance])\r\n        word_freq = dict(zip(vectorizer.get_feature_names_out(), vectorized_words.toarray().tolist()[0]))\r\n        return word_freq\r\n    \r\n    def classify_utterance(utterance):\r\n        \"\"\"\r\n        Classifies the given utterance into categories like emotional tone or speech act.\r\n        Placeholder function - actual implementation required.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            str: The classified category of the utterance.\r\n        \"\"\"\r\n        # Placeholder: Implement a classifier or use an existing model\r\n        return \"general_inquiry\"\r\n    \r\n    def ask_openai(utterance):\r\n        \"\"\"\r\n        Processes the given user utterance and generates a response using OpenAI's API.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            str: The generated response from the bot.\r\n        \"\"\"\r\n        global conversation_history\r\n        # Analyze word frequency and classify utterance\r\n        word_freq = analyze_word_frequency(utterance)\r\n        utterance_category = classify_utterance(utterance)\r\n    \r\n        # Append the user's utterance and additional info to the conversation history\r\n        conversation_history.append({\"role\": \"user\", \"content\": utterance, \"word_freq\": word_freq, \"category\": utterance_category})\r\n    \r\n        try:\r\n            # Construct a prompt for the completion model\r\n            prompt = create_completion_prompt(utterance)\r\n            # Set a maximum token limit for the prompt\r\n            max_prompt_tokens = 500\r\n            prompt_length = len(prompt.split())\r\n            remaining_tokens = max(20, max_prompt_tokens - prompt_length)\r\n    \r\n            # Make a call to the completion model\r\n            response_completion = client.completions.create(\r\n                model=\"text-davinci-003\",\r\n                prompt=prompt,\r\n                temperature=0.7,\r\n                max_tokens=remaining_tokens\r\n            )\r\n            # Extract and clean the response\r\n            completion_response = response_completion.choices[0].text.strip()\r\n            # Append the response to the conversation history\r\n            conversation_history.append({\"role\": \"assistant\", \"content\": completion_response})\r\n        except Exception as e:\r\n            # Handle exceptions and return the error message\r\n            completion_response = f\"An error occurred: {str(e)}\"\r\n    \r\n        try:\r\n            # Make a call to the chat model\r\n            response_chat = client.chat.completions.create(\r\n                model=\"gpt-3.5-turbo\",\r\n                max_tokens=remaining_tokens,\r\n                messages=create_chat_messages_for_api()\r\n            )\r\n            # Extract and clean the chat model response\r\n            chat_response = response_chat.choices[0].message.content.strip()\r\n            # Append the response to the conversation history\r\n            conversation_history.append({\"role\": \"assistant\", \"content\": chat_response})\r\n        except Exception as e:\r\n            # Handle exceptions and return the error message\r\n            chat_response = f\"An error occurred: {str(e)}\"\r\n    \r\n        # Decide which response to return\r\n        return decide_response(completion_response, chat_response)\r\n    \r\n    def create_completion_prompt(utterance):\r\n        \"\"\"\r\n        Creates a completion prompt with a predefined context for the OpenAI model.\r\n    \r\n        Args:\r\n            utterance (str): The user's input message.\r\n    \r\n        Returns:\r\n            str: The constructed prompt for the OpenAI model.\r\n        \"\"\"\r\n        # Predefined context for the AI model\r\n        introduction = (\r\n            \"You are an expert real estate agent well-versed in the Toronto and Ontario housing market. \"\r\n            \"You have comprehensive knowledge of local real estate laws, regulations, market trends, \"\r\n            \"property valuations, and lending practices. You provide detailed, accurate, and up-to-date information. \"\r\n            \"Your responses are professional and adhere to the current legal and market standards.\"\r\n        )\r\n        # Combine the context with the user's question\r\n        prompt = introduction + f\"Question: {utterance}Response:\"\r\n        return prompt\r\n    \r\n    def create_chat_messages_for_api():\r\n        \"\"\"\r\n        Formats the conversation history for the chat model API call.\r\n    \r\n        Returns:\r\n            list: A list of messages formatted for the chat model, excluding 'category' and 'word_freq'.\r\n        \"\"\"\r\n        formatted_history = []\r\n        for message in conversation_history:\r\n            formatted_message = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\r\n            formatted_history.append(formatted_message)\r\n        \r\n        return formatted_history\r\n    \r\n    def decide_response(completion_response, chat_response):\r\n        \"\"\"\r\n        Decides which response to use based on relevance and redundancy checks.\r\n    \r\n        Args:\r\n            completion_response (str): The response from the completion model.\r\n            chat_response (str): The response from the chat model.\r\n    \r\n        Returns:\r\n            str: The chosen response after evaluation.\r\n        \"\"\"\r\n        # Evaluate and return the most appropriate response\r\n        if is_response_relevant(completion_response) and not is_response_relevant(chat_response):\r\n            return completion_response\r\n        elif is_response_relevant(chat_response) and not is_response_relevant(completion_response):\r\n            return chat_response\r\n        elif is_response_redundant(completion_response, chat_response):\r\n            return completion_response\r\n        else:\r\n            return f\"Response 1: {completion_response}Response 2: {chat_response}\"\r\n    \r\n    def is_response_relevant(response):\r\n        \"\"\"\r\n        Checks if the given response is relevant based on predefined criteria.\r\n    \r\n        Args:\r\n            response (str): The response to evaluate.\r\n    \r\n        Returns:\r\n            bool: True if the response is relevant, False otherwise.\r\n        \"\"\"\r\n        important_keywords = set([\"real estate\", \"market\", \"property\", \"Toronto\", \"Ontario\", \"laws\", \"regulations\", \"lending\"])\r\n        response_lower = response.lower()\r\n        for keyword in important_keywords:\r\n            if keyword in response_lower:\r\n                return True\r\n        min_length, max_length = 20, 300\r\n        if len(response) < min_length or len(response) > max_length:\r\n            return False\r\n        return True\r\n    \r\n    def is_response_redundant(response1, response2):\r\n        \"\"\"\r\n        Checks if two responses are redundant to each other.\r\n    \r\n        Args:\r\n            response1 (str): The first response.\r\n            response2 (str): The second response.\r\n    \r\n        Returns:\r\n            bool: True if the responses are redundant, False otherwise.\r\n        \"\"\"\r\n        words1 = set(response1.lower().split())\r\n        words2 = set(response2.lower().split())\r\n        common_words = words1.intersection(words2)\r\n        threshold = 0.5\r\n        redundancy_ratio = len(common_words) / min(len(words1), len(words2))\r\n        return redundancy_ratio > threshold`;\r\n\r\n    const style = {\r\n        container: {\r\n            padding: theme.spacing(3),\r\n            color: theme.palette.common.white,\r\n            backgroundColor: theme.palette.background.default,\r\n            minHeight: '100vh',\r\n            display: 'flex',\r\n            flexDirection: 'column',\r\n            alignItems: 'center',\r\n            justifyContent: 'center',\r\n            maxWidth: '600px', // Set max width to 600px\r\n            marginLeft: 'auto', // Center the container\r\n            marginRight: 'auto',\r\n            [theme.breakpoints.down('md')]: { // Adjust for medium and smaller devices\r\n                maxWidth: '100%',\r\n                padding: theme.spacing(2),\r\n            },\r\n        },\r\n        header: {\r\n            marginBottom: theme.spacing(2),\r\n        },\r\n        paragraph: {\r\n            marginBottom: theme.spacing(1),\r\n            textAlign: 'left', // Align text to the left\r\n        },\r\n        featureBox: {\r\n            marginTop: theme.spacing(4),\r\n            textAlign: 'left',\r\n        },\r\n        featureHeading: {\r\n            marginBottom: theme.spacing(1),\r\n        },\r\n        motivationBox: {\r\n            marginTop: theme.spacing(4),\r\n            textAlign: 'left',\r\n        },\r\n        codeBox: {\r\n            marginTop: theme.spacing(4),\r\n            backgroundColor: '#1e1e1e', \r\n            padding: theme.spacing(2),\r\n            borderRadius: theme.shape.borderRadius,\r\n            boxShadow: theme.shadows[1],\r\n            overflowX: 'auto',\r\n            color: '#f8f8f2', // Adjust the text color if needed\r\n            [theme.breakpoints.down('sm')]: { // Adjust for small devices\r\n                fontSize: '0.8em', // Smaller font size for small devices\r\n                width: '100%'\r\n            },\r\n            \r\n        },\r\n    };\r\n\r\n    return (\r\n        <Box sx={style.container}>\r\n            <Typography variant=\"h2\" sx={style.header}>RealEstate AI Bot</Typography>\r\n            \r\n            <Typography variant=\"body1\" sx={style.paragraph}>\r\n                This script is the backbone of a Real Estate Assistant Discord Bot, leveraging OpenAI's GPT models for handling real estate inquiries, particularly within the Toronto and Ontario markets. It's adept at maintaining conversation histories to ensure contextually aware interactions, while also utilizing advanced techniques like word frequency analysis and emotional tone classification to understand and respond to user queries effectively.\r\n            </Typography>\r\n\r\n            <Typography variant=\"body1\" sx={style.paragraph}>\r\n                Furthermore, the script is intricately designed to craft detailed prompts for the OpenAI API, ensuring each response is tailored and relevant. Its sophisticated logic not only manages dialogue history but also evaluates the relevance and redundancy of potential responses. This seamless integration with a Discord bot client allows for dynamic interactions in a server environment, enhancing user engagement.\r\n            </Typography>\r\n\r\n\r\n            <Box sx={style.featureBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Key Features:</Typography>\r\n                <ul>\r\n                    <li><Typography variant=\"body1\">Utilizes OpenAI's powerful language models to answer real estate-related queries.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Analyzes word frequency vectors for better understanding of queries.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Classifies utterances based on emotional tone or speech act.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Maintains conversation context for more coherent and relevant interactions.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Employs two distinct models (completion and chat) for varied response generation.</Typography></li>\r\n                    <li><Typography variant=\"body1\">Implements relevance and redundancy checks to optimize response quality.</Typography></li>\r\n                </ul>\r\n            </Box>\r\n\r\n            <Box sx={style.motivationBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Project Motivation:</Typography>\r\n                <Typography variant=\"body1\">\r\n                    This bot was created as an experiment to see if it's possible to replace the need for a traditional real estate agent with a bot trained on the right data. The goal is to provide instant, accurate, and personalized real estate advice using advanced AI technology.\r\n                </Typography>\r\n            </Box>\r\n\r\n            <Box sx={style.motivationBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Discord Integration: Streamlining Development</Typography>\r\n                <Typography variant=\"body1\">\r\n                To enhance the development of the RealEstate AI Bot, I integrated it with Discord. This decision significantly accelerated the initial setup by eliminating the need to create a custom GUI. Utilizing Discord's existing chat interface allowed for immediate and efficient interaction with the bot, saving considerable time and focusing on its core functionalities.\r\n                </Typography>\r\n            </Box>\r\n\r\n\r\n\r\n            <Box sx={style.featureBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Dependencies:</Typography>\r\n                <ul>\r\n                    <li><Typography variant=\"body1\">OpenAI Python client library</Typography></li>\r\n                    <li><Typography variant=\"body1\">Python 3.6 or higher</Typography></li>\r\n                    <li><Typography variant=\"body1\">Discord.py library for Discord bot integration</Typography></li>\r\n                    <li><Typography variant=\"body1\">spaCy for NLP tasks</Typography></li>\r\n                    <li><Typography variant=\"body1\">sklearn for machine learning tasks</Typography></li>\r\n                </ul>\r\n            </Box>\r\n\r\n            <Box sx={style.codeBox}>\r\n                <Typography variant=\"h4\" sx={style.featureHeading}>Python Code:</Typography>\r\n                <SyntaxHighlighter language=\"python\" style={dark}>\r\n                    {pythonCode}\r\n                </SyntaxHighlighter>\r\n            </Box>\r\n        </Box>\r\n    );\r\n};\r\n\r\nexport default RealEstateBot;\r\n"],"mappings":"AAAA,MAAO,CAAAA,KAAK,KAAM,OAAO,CACzB,OAASC,GAAG,CAAUC,UAAU,CAAEC,QAAQ,KAAQ,eAAe,CACjE,OAASC,WAAW,KAAQ,kBAAkB,CAC9C,OAASC,KAAK,GAAI,CAAAC,iBAAiB,KAAQ,0BAA0B,CACrE,OAASC,IAAI,KAAQ,gDAAgD,CAAC,OAAAC,GAAA,IAAAC,IAAA,gCAAAC,IAAA,IAAAC,KAAA,yBAEtE,KAAM,CAAAC,aAAa,CAAGA,CAAA,GAAM,CACxB,KAAM,CAAAC,QAAQ,CAAGT,WAAW,CAAC,CAAC,CAC9B,KAAM,CAAAU,KAAK,CAAGX,QAAQ,CAAC,CAAC,CAExB,KAAM,CAAAY,UAAU,+pQA0MwB,CAExC,KAAM,CAAAC,KAAK,CAAG,CACVC,SAAS,CAAE,CACPC,OAAO,CAAEJ,KAAK,CAACK,OAAO,CAAC,CAAC,CAAC,CACzBC,KAAK,CAAEN,KAAK,CAACO,OAAO,CAACC,MAAM,CAACC,KAAK,CACjCC,eAAe,CAAEV,KAAK,CAACO,OAAO,CAACI,UAAU,CAACC,OAAO,CACjDC,SAAS,CAAE,OAAO,CAClBC,OAAO,CAAE,MAAM,CACfC,aAAa,CAAE,QAAQ,CACvBC,UAAU,CAAE,QAAQ,CACpBC,cAAc,CAAE,QAAQ,CACxBC,QAAQ,CAAE,OAAO,CAAE;AACnBC,UAAU,CAAE,MAAM,CAAE;AACpBC,WAAW,CAAE,MAAM,CACnB,CAACpB,KAAK,CAACqB,WAAW,CAACC,IAAI,CAAC,IAAI,CAAC,EAAG,CAAE;AAC9BJ,QAAQ,CAAE,MAAM,CAChBd,OAAO,CAAEJ,KAAK,CAACK,OAAO,CAAC,CAAC,CAC5B,CACJ,CAAC,CACDkB,MAAM,CAAE,CACJC,YAAY,CAAExB,KAAK,CAACK,OAAO,CAAC,CAAC,CACjC,CAAC,CACDoB,SAAS,CAAE,CACPD,YAAY,CAAExB,KAAK,CAACK,OAAO,CAAC,CAAC,CAAC,CAC9BqB,SAAS,CAAE,MAAQ;AACvB,CAAC,CACDC,UAAU,CAAE,CACRC,SAAS,CAAE5B,KAAK,CAACK,OAAO,CAAC,CAAC,CAAC,CAC3BqB,SAAS,CAAE,MACf,CAAC,CACDG,cAAc,CAAE,CACZL,YAAY,CAAExB,KAAK,CAACK,OAAO,CAAC,CAAC,CACjC,CAAC,CACDyB,aAAa,CAAE,CACXF,SAAS,CAAE5B,KAAK,CAACK,OAAO,CAAC,CAAC,CAAC,CAC3BqB,SAAS,CAAE,MACf,CAAC,CACDK,OAAO,CAAE,CACLH,SAAS,CAAE5B,KAAK,CAACK,OAAO,CAAC,CAAC,CAAC,CAC3BK,eAAe,CAAE,SAAS,CAC1BN,OAAO,CAAEJ,KAAK,CAACK,OAAO,CAAC,CAAC,CAAC,CACzB2B,YAAY,CAAEhC,KAAK,CAACiC,KAAK,CAACD,YAAY,CACtCE,SAAS,CAAElC,KAAK,CAACmC,OAAO,CAAC,CAAC,CAAC,CAC3BC,SAAS,CAAE,MAAM,CACjB9B,KAAK,CAAE,SAAS,CAAE;AAClB,CAACN,KAAK,CAACqB,WAAW,CAACC,IAAI,CAAC,IAAI,CAAC,EAAG,CAAE;AAC9Be,QAAQ,CAAE,OAAO,CAAE;AACnBC,KAAK,CAAE,MACX,CAEJ,CACJ,CAAC,CAED,mBACIzC,KAAA,CAACV,GAAG,EAACoD,EAAE,CAAErC,KAAK,CAACC,SAAU,CAAAqC,QAAA,eACrB7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,IAAI,CAACF,EAAE,CAAErC,KAAK,CAACqB,MAAO,CAAAiB,QAAA,CAAC,mBAAiB,CAAY,CAAC,cAEzE7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAACF,EAAE,CAAErC,KAAK,CAACuB,SAAU,CAAAe,QAAA,CAAC,wbAEjD,CAAY,CAAC,cAEb7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAACF,EAAE,CAAErC,KAAK,CAACuB,SAAU,CAAAe,QAAA,CAAC,0ZAEjD,CAAY,CAAC,cAGb3C,KAAA,CAACV,GAAG,EAACoD,EAAE,CAAErC,KAAK,CAACyB,UAAW,CAAAa,QAAA,eACtB7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,IAAI,CAACF,EAAE,CAAErC,KAAK,CAAC2B,cAAe,CAAAW,QAAA,CAAC,eAAa,CAAY,CAAC,cAC7E3C,KAAA,OAAA2C,QAAA,eACI7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,mFAAiF,CAAY,CAAC,CAAI,CAAC,cACnI7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,sEAAoE,CAAY,CAAC,CAAI,CAAC,cACtH7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,8DAA4D,CAAY,CAAC,CAAI,CAAC,cAC9G7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,6EAA2E,CAAY,CAAC,CAAI,CAAC,cAC7H7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,mFAAiF,CAAY,CAAC,CAAI,CAAC,cACnI7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,0EAAwE,CAAY,CAAC,CAAI,CAAC,EAC1H,CAAC,EACJ,CAAC,cAEN3C,KAAA,CAACV,GAAG,EAACoD,EAAE,CAAErC,KAAK,CAAC4B,aAAc,CAAAU,QAAA,eACzB7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,IAAI,CAACF,EAAE,CAAErC,KAAK,CAAC2B,cAAe,CAAAW,QAAA,CAAC,qBAAmB,CAAY,CAAC,cACnF7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,yQAE5B,CAAY,CAAC,EACZ,CAAC,cAEN3C,KAAA,CAACV,GAAG,EAACoD,EAAE,CAAErC,KAAK,CAAC4B,aAAc,CAAAU,QAAA,eACzB7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,IAAI,CAACF,EAAE,CAAErC,KAAK,CAAC2B,cAAe,CAAAW,QAAA,CAAC,+CAA6C,CAAY,CAAC,cAC7G7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,2WAE5B,CAAY,CAAC,EACZ,CAAC,cAIN3C,KAAA,CAACV,GAAG,EAACoD,EAAE,CAAErC,KAAK,CAACyB,UAAW,CAAAa,QAAA,eACtB7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,IAAI,CAACF,EAAE,CAAErC,KAAK,CAAC2B,cAAe,CAAAW,QAAA,CAAC,eAAa,CAAY,CAAC,cAC7E3C,KAAA,OAAA2C,QAAA,eACI7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,8BAA4B,CAAY,CAAC,CAAI,CAAC,cAC9E7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,sBAAoB,CAAY,CAAC,CAAI,CAAC,cACtE7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,gDAA8C,CAAY,CAAC,CAAI,CAAC,cAChG7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,qBAAmB,CAAY,CAAC,CAAI,CAAC,cACrE7C,IAAA,OAAA6C,QAAA,cAAI7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,OAAO,CAAAD,QAAA,CAAC,oCAAkC,CAAY,CAAC,CAAI,CAAC,EACpF,CAAC,EACJ,CAAC,cAEN3C,KAAA,CAACV,GAAG,EAACoD,EAAE,CAAErC,KAAK,CAAC6B,OAAQ,CAAAS,QAAA,eACnB7C,IAAA,CAACP,UAAU,EAACqD,OAAO,CAAC,IAAI,CAACF,EAAE,CAAErC,KAAK,CAAC2B,cAAe,CAAAW,QAAA,CAAC,cAAY,CAAY,CAAC,cAC5E7C,IAAA,CAACH,iBAAiB,EAACkD,QAAQ,CAAC,QAAQ,CAACxC,KAAK,CAAET,IAAK,CAAA+C,QAAA,CAC5CvC,UAAU,CACI,CAAC,EACnB,CAAC,EACL,CAAC,CAEd,CAAC,CAED,cAAe,CAAAH,aAAa"},"metadata":{},"sourceType":"module","externalDependencies":[]}